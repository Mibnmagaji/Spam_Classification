{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do text classification, we need to extract features from text content since machine can't read words like we do. However, there doesn't exist a single best way to generate information from context. Therefore we will try various word embedding method including bag-of-words models and vector-space models, and compare its performance by using neural network models for classfication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "import string\n",
    "import nltk\n",
    "import gc\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from keras import metrics\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, concatenate, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read in the spam file and remove non informative columns consists of NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "sms = sms.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "sms = sms.rename(columns={\"v1\":\"class\", \"v2\":\"text\"})\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data contains two columns, the email text and class label of ham/spam. Next, we will do some basic EDA of the spam data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                                               \n",
       "      count unique                                                top freq\n",
       "class                                                                     \n",
       "ham    4825   4516                             Sorry, I'll call later   30\n",
       "spam    747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.groupby('class').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000019EEC05D470>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19eebfb88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sms['length'] = sms['text'].apply(len)\n",
    "sms.hist(column='length', bins=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the EDA above that the proportion of an email being ham is about 13%, and that most of the emails has length below 180 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will perform bag-of-word models for word embedding. Two methods we will be using are count encoding and tf-idf encoding. First we specify how many of the most common words in vocabulary we like to use, in our case it would be 1000. Then for each document, we have a 1000 dimension vector that is zero if a word appears and non-zero otherwise. For count encoding, the non-zero value is the time a word appear in document, and tf-idf is the score calculated by term frequency (raw count or term frequency) in document times log of total number of documents over the number of document which the term appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label of first six document\n",
      "[0 0 1 0 0 1]\n",
      "\n",
      "\n",
      "Count encoded matrix of first six document\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 3. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 2. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "Tf-idf encoded matrix of first six document\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         3.06822641 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         1.46707378 1.46202632 ... 0.         0.         0.        ]\n",
      " [0.         0.         2.47542574 ... 0.         0.         0.        ]]\n",
      "\n",
      "\n",
      "Shape of encoded label, count matrix, and tfidf matrix\n",
      "(5572,) (5572, 1000) (5572, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_max = 1000 #vocabulary size\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(sms['class'])\n",
    "\n",
    "#one hot encoding\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(sms['text'])\n",
    "count_texts = tok.texts_to_matrix(sms['text'], mode='count')\n",
    "tf_idf_texts = tok.texts_to_matrix(sms['text'], mode='tfidf')\n",
    "print('Encoded label of first six document')\n",
    "print(tags[:6])\n",
    "print('\\n')\n",
    "print('Count encoded matrix of first six document')\n",
    "print(count_texts[:6])\n",
    "print('\\n')\n",
    "print('Tf-idf encoded matrix of first six document')\n",
    "print(tf_idf_texts[:6])\n",
    "print('\\n')\n",
    "print('Shape of encoded label, count matrix, and tfidf matrix')\n",
    "print(tags.shape,count_texts.shape, tf_idf_texts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then try different type of method to encode our corpus, which is so-called vector-space models. The biggest difference comparing to bag-of-words is that vector-space models encode each word, instead of document into a fixed dimension vector. Therefore the output for each document is a matrix instead of vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our task, we will be using the famous Word2vec model, trained by CBOW and Skip-Gram models. Word2vec has serveral advantages, one is that it encodes each word into a fixed dimension vector, reducing the curse of dimension effect of large corpus in bag-of-words, another is that it is capable of preserving semantic information of words, such as Queen - Woman + Man = King, which is pretty useful in many tasks. However, Word2vec requires large amount of context to train, therefore we will be using pre-trained Googlenews word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "word2vecDict = word2vec.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the pre-trained model, which is length of 300 for each word, we will then create a embedding matrix of our corpus with each word's weights corresponding to word vectors in pre-trained model of the same word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000000 word vectors.\n",
      "Embedded matrix shape : (1000, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = 300\n",
    "embeddings_index = dict()\n",
    "for word in word2vecDict.wv.vocab:\n",
    "    embeddings_index[word] = word2vecDict.word_vec(word)\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))            \n",
    "gc.collect()\n",
    "\n",
    "num_words = 1000\n",
    "embedding_matrix = np.zeros((num_words, 300))\n",
    "for word, i in tok.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print('Embedded matrix shape :', embedding_matrix.shape)\n",
    "del(embeddings_index)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to model CNN on our extracted features! The model structure of CNN is similiar to the one I described on Readme section. Since the model is intended for vector-space features, we will try with Word2vec features first. We will be using Keras, and we need to preprocess our input first. Steps for preprocessing are : For given max number (1000) of most frequent vocabulary, encode each word into an unique interger(0-999) and transfer each document into a sequence of the intergers, next we pad the sequence into length of given max length (180) with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence encoding of first text message\n",
      "[50, 469, 841, 751, 657, 64, 8, 89, 121, 349, 147, 67, 58, 144]\n",
      "\n",
      "\n",
      "padded sequence of first text message\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  50 469 841 751 657  64   8  89 121 349 147  67  58 144]\n",
      "\n",
      "\n",
      "shape of padded sequence\n",
      "(5572, 180)\n"
     ]
    }
   ],
   "source": [
    "# preprocess for embedding layer in CNN\n",
    "max_len = 180\n",
    "cnn_texts_seq = tok.texts_to_sequences(sms['text'])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print('sequence encoding of first text message')\n",
    "print(cnn_texts_seq[0])\n",
    "print('\\n')\n",
    "print('padded sequence of first text message')\n",
    "print(cnn_texts_mat[0])\n",
    "print('\\n')\n",
    "print('shape of padded sequence')\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 64 filters for each of bigram, trigram, and fourgram extractor, and we add a dropout layer within our dense layers to regularize our model. Another thing to mention is that we should set trainable = False for embedding layer if we are using pre-trained word vectors and we don't want the weight to be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 180)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 180, 300)     300000      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 179, 64)      38464       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 178, 64)      57664       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 177, 64)      76864       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 64)           0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 64)           0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 64)           0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192)          0           global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          24704       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1)            0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 497,825\n",
      "Trainable params: 197,825\n",
      "Non-trainable params: 300,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Input layer\n",
    "text_input = Input(shape=(180,), dtype='int32')\n",
    "#Pretrained Embedding layer\n",
    "text_encoder = Embedding(1000, 300, weights=[embedding_matrix], input_length=180, trainable=False)(text_input)\n",
    "#Parallel 1D convolutional layer and max pooling Layer with different kernel size\n",
    "bigram_branch = Conv1D(filters=64, kernel_size=2, padding='valid', activation='relu', strides=1)(text_encoder)\n",
    "bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "trigram_branch = Conv1D(filters=64, kernel_size=3, padding='valid', activation='relu', strides=1)(text_encoder)\n",
    "trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "fourgram_branch = Conv1D(filters=64, kernel_size=4, padding='valid', activation='relu', strides=1)(text_encoder)\n",
    "fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "#Concat layer\n",
    "merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "#Dense layer\n",
    "merged = Dense(128, activation='relu')(merged)\n",
    "#Dropout Layer\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = Dense(1)(merged)\n",
    "#Output layer\n",
    "output = Activation('sigmoid')(merged)\n",
    "model = Model(inputs=[text_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 26s 6ms/step - loss: 0.1421 - acc: 0.9536 - val_loss: 0.0487 - val_acc: 0.9830\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 26s 6ms/step - loss: 0.0312 - acc: 0.9915 - val_loss: 0.0540 - val_acc: 0.9794\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 26s 6ms/step - loss: 0.0153 - acc: 0.9962 - val_loss: 0.0378 - val_acc: 0.9883\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 25s 6ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0420 - val_acc: 0.9874\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 25s 6ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0640 - val_acc: 0.9865\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 29s 6ms/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0440 - val_acc: 0.9865\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 27s 6ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0464 - val_acc: 0.9865\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 30s 7ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0477 - val_acc: 0.9865\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 27s 6ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0503 - val_acc: 0.9865\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 28s 6ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0498 - val_acc: 0.9865\n",
      "\n",
      "\n",
      "Best validation score : 0.9883408071748879\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)     \n",
    "history = model.fit(cnn_texts_mat,tags,batch_size=32,epochs=10,verbose=1,validation_split=0.2, shuffle=False)\n",
    "print('\\n')\n",
    "word2vec_embed_score = max(history.history['val_acc'])\n",
    "print('Best validation score : {}'.format(word2vec_embed_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For machine learning task such as regression or classification, sometimes we would like to train our embedding weight from scratch. It is slower but might result in an embedding matrix more suitable for specific dataset since the weights are now parameters that will be updated to minimize our loss function. The other setting for our model is same as above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 180)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 180, 300)     300000      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 179, 64)      38464       embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 178, 64)      57664       embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 177, 64)      76864       embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 64)           0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 64)           0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 64)           0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 192)          0           global_max_pooling1d_19[0][0]    \n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          24704       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            129         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1)            0           dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 497,825\n",
      "Trainable params: 497,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Input layer\n",
    "text_input = Input(shape=(180,), dtype='int32')\n",
    "#Embedding layer\n",
    "text_encoder = Embedding(1000, 300, input_length=180, trainable=True)(text_input)\n",
    "#Parallel 1D convolutional layer and max pooling Layer with different kernel size\n",
    "bigram_branch = Conv1D(filters=64, kernel_size=2, padding='valid', activation='relu', strides=1)(text_encoder)\n",
    "bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "trigram_branch = Conv1D(filters=64, kernel_size=3, padding='valid', activation='relu', strides=1)(text_encoder)\n",
    "trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "fourgram_branch = Conv1D(filters=64, kernel_size=4, padding='valid', activation='relu', strides=1)(text_encoder)\n",
    "fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "#Concat layer\n",
    "merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "#Dense layer\n",
    "merged = Dense(128, activation='relu')(merged)\n",
    "#Dropout Layer\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = Dense(1)(merged)\n",
    "#Output layer\n",
    "output = Activation('sigmoid')(merged)\n",
    "model1 = Model(inputs=[text_input], outputs=[output])\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 37s 8ms/step - loss: 0.1974 - acc: 0.9313 - val_loss: 0.0592 - val_acc: 0.9812\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 33s 8ms/step - loss: 0.0313 - acc: 0.9912 - val_loss: 0.0512 - val_acc: 0.9839\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 33s 7ms/step - loss: 0.0109 - acc: 0.9973 - val_loss: 0.0547 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 32s 7ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0586 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 31s 7ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0603 - val_acc: 0.9848\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 34s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0622 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 35s 8ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0668 - val_acc: 0.9874\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0708 - val_acc: 0.9865\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 32s 7ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0732 - val_acc: 0.9865\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 33s 7ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0729 - val_acc: 0.9865\n",
      "\n",
      "\n",
      "Best validation score : 0.9874439461883409\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)     \n",
    "history = model1.fit(cnn_texts_mat,tags,batch_size=32,epochs=10,verbose=1,validation_split=0.2, shuffle=False)\n",
    "print('\\n')\n",
    "nn_embed_score = max(history.history['val_acc'])\n",
    "print('Best validation score : {}'.format(nn_embed_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods reach similiar score in terms of accuracy, with Word2vec embedding slightly better. Next we will try the same model on our count and tfidf features respectively. The input shape is now (1000,1) instead of (180, 300), and we will remove the embedding layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 999, 64)      192         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 998, 64)      256         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 997, 64)      320         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 64)           0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 64)           0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 64)           0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 192)          0           global_max_pooling1d_25[0][0]    \n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "                                                                 global_max_pooling1d_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          24704       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            129         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1)            0           dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,601\n",
      "Trainable params: 25,601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Input layer\n",
    "text_input = Input(shape=(1000,1), dtype='float32')\n",
    "#Parallel 1D convolutional layer and max pooling Layer with different kernel size\n",
    "bigram_branch = Conv1D(filters=64, kernel_size=2, padding='valid', activation='relu', strides=1)(text_input)\n",
    "bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "trigram_branch = Conv1D(filters=64, kernel_size=3, padding='valid', activation='relu', strides=1)(text_input)\n",
    "trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "fourgram_branch = Conv1D(filters=64, kernel_size=4, padding='valid', activation='relu', strides=1)(text_input)\n",
    "fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "#Concat layer\n",
    "merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "#Dense layer\n",
    "merged = Dense(128, activation='relu')(merged)\n",
    "#Dropout Layer\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = Dense(1)(merged)\n",
    "#Output layer\n",
    "output = Activation('sigmoid')(merged)\n",
    "model2 = Model(inputs=[text_input], outputs=[output])\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reshaped matrix\n",
      "(5572, 1000, 1)\n",
      "\n",
      "\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 39s 9ms/step - loss: 0.3902 - acc: 0.8604 - val_loss: 0.3525 - val_acc: 0.8700\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 37s 8ms/step - loss: 0.3550 - acc: 0.8649 - val_loss: 0.3453 - val_acc: 0.8700\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 38s 8ms/step - loss: 0.3506 - acc: 0.8649 - val_loss: 0.3461 - val_acc: 0.8700\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 37s 8ms/step - loss: 0.3502 - acc: 0.8649 - val_loss: 0.3414 - val_acc: 0.8700\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 38s 9ms/step - loss: 0.3486 - acc: 0.8649 - val_loss: 0.3418 - val_acc: 0.8700\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 37s 8ms/step - loss: 0.3475 - acc: 0.8649 - val_loss: 0.3408 - val_acc: 0.8700\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 38s 8ms/step - loss: 0.3487 - acc: 0.8649 - val_loss: 0.3413 - val_acc: 0.8700\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 38s 8ms/step - loss: 0.3458 - acc: 0.8649 - val_loss: 0.3394 - val_acc: 0.8700\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 37s 8ms/step - loss: 0.3449 - acc: 0.8649 - val_loss: 0.3389 - val_acc: 0.8700\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 38s 9ms/step - loss: 0.3433 - acc: 0.8649 - val_loss: 0.3375 - val_acc: 0.8700\n",
      "\n",
      "\n",
      "Best validation score : 0.8699551571110439\n"
     ]
    }
   ],
   "source": [
    "reshaped_count_texts = count_texts.reshape((5572,1000,1))     \n",
    "print('Shape of reshaped matrix')\n",
    "print(reshaped_count_texts.shape)\n",
    "print('\\n')\n",
    "np.random.seed(1337)\n",
    "history = model2.fit(reshaped_count_texts,tags,batch_size=32,epochs=10,verbose=1,validation_split=0.2, shuffle=False)\n",
    "print('\\n')\n",
    "count_score = max(history.history['val_acc'])\n",
    "print('Best validation score : {}'.format(count_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 37s 8ms/step - loss: 0.4448 - acc: 0.8629 - val_loss: 0.3922 - val_acc: 0.8744\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.4034 - acc: 0.8676 - val_loss: 0.3801 - val_acc: 0.8744\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.3921 - acc: 0.8674 - val_loss: 0.3635 - val_acc: 0.8753\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.3787 - acc: 0.8685 - val_loss: 0.3518 - val_acc: 0.8744\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.3688 - acc: 0.8694 - val_loss: 0.3562 - val_acc: 0.8700\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.3613 - acc: 0.8678 - val_loss: 0.3385 - val_acc: 0.8744\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.3625 - acc: 0.8674 - val_loss: 0.3382 - val_acc: 0.8744\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.3600 - acc: 0.8683 - val_loss: 0.3349 - val_acc: 0.8735\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.3558 - acc: 0.8683 - val_loss: 0.3342 - val_acc: 0.8691\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 36s 8ms/step - loss: 0.3533 - acc: 0.8683 - val_loss: 0.3314 - val_acc: 0.8735\n",
      "\n",
      "\n",
      "Best validation score : 0.8753363230303264\n"
     ]
    }
   ],
   "source": [
    "reshaped_tf_idf_texts = tf_idf_texts.reshape((5572,1000,1))\n",
    "np.random.seed(1337)     \n",
    "history = model2.fit(reshaped_tf_idf_texts,tags,batch_size=32,epochs=10,verbose=1,validation_split=0.2, shuffle=False)\n",
    "print('\\n')\n",
    "tf_idf_score = max(history.history['val_acc'])\n",
    "print('Best validation score : {}'.format(tf_idf_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models have bad results, which is not unexpectable. The reason is that our CNN models are intended for embedding matrix, when it is used on bag-of-words features, it is unable to capture n-gram information because the input are not ordered words. Therefore, we will model count and tf-idf features again with simple neural network instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 644,097\n",
      "Trainable params: 644,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 644,097\n",
      "Trainable params: 644,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.summary()\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.binary_accuracy])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 2s 503us/step - loss: 0.0035 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.0956 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 2s 496us/step - loss: 0.0015 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1097 - val_acc: 0.9865 - val_binary_accuracy: 0.9865\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 2s 512us/step - loss: 0.0012 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1177 - val_acc: 0.9865 - val_binary_accuracy: 0.9865\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 2s 490us/step - loss: 0.0011 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1237 - val_acc: 0.9865 - val_binary_accuracy: 0.9865\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 2s 497us/step - loss: 9.5086e-04 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1285 - val_acc: 0.9865 - val_binary_accuracy: 0.9865\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 2s 517us/step - loss: 0.0010 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1297 - val_acc: 0.9865 - val_binary_accuracy: 0.9865\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 2s 513us/step - loss: 0.0011 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1245 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 2s 511us/step - loss: 0.0011 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1275 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 2s 514us/step - loss: 0.0011 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1290 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 2s 523us/step - loss: 0.0010 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.1313 - val_acc: 0.9874 - val_binary_accuracy: 0.9874\n",
      "\n",
      "\n",
      "Best validation score : 0.9874439461883409\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)\n",
    "history = model3.fit(count_texts,tags,batch_size=32,epochs=10,verbose=1,validation_split=0.2, shuffle=False)\n",
    "print('\\n')\n",
    "count_score = max(history.history['val_acc'])\n",
    "print('Best validation score : {}'.format(count_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 2s 511us/step - loss: 0.0013 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.2374 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 2s 489us/step - loss: 9.7121e-04 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.2291 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 2s 504us/step - loss: 9.2776e-04 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.2292 - val_acc: 0.9803 - val_binary_accuracy: 0.9803\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 2s 490us/step - loss: 9.6891e-04 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.2046 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 2s 516us/step - loss: 0.0014 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1983 - val_acc: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 2s 507us/step - loss: 0.0032 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.2580 - val_acc: 0.9794 - val_binary_accuracy: 0.9794\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 2s 497us/step - loss: 0.0078 - acc: 0.9978 - binary_accuracy: 0.9978 - val_loss: 0.2471 - val_acc: 0.9785 - val_binary_accuracy: 0.9785\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 2s 518us/step - loss: 0.0029 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.2206 - val_acc: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 2s 513us/step - loss: 9.7446e-04 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.2279 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 2s 517us/step - loss: 0.0012 - acc: 0.9998 - binary_accuracy: 0.9998 - val_loss: 0.2247 - val_acc: 0.9803 - val_binary_accuracy: 0.9803\n",
      "\n",
      "\n",
      "Best validation score : 0.9829596412556054\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)     \n",
    "history = model3.fit(tf_idf_texts,tags,batch_size=32,epochs=10,verbose=1,validation_split=0.2, shuffle=False)\n",
    "print('\\n')\n",
    "tf_idf_score = max(history.history['val_acc'])\n",
    "print('Best validation score : {}'.format(tf_idf_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the score improved a lot comparing to using CNN on the same features. Count features reaches a score similiar to vector-space features, while tf-idf features score a little worse. In conclusion, we learned that more complicated models does not suit all kind of data, sometimes we need to think of the problem statement before we choose our model. Further extension of this project can be testing performance on larger dataset, or using simple RNN or LSTM, which is adapted by many researchers, to do text classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
